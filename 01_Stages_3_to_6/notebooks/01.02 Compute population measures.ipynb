{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "\n",
    "import os,sys\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.gridspec as gridspec\n",
    "\n",
    "from collections import defaultdict, Counter, OrderedDict\n",
    "\n",
    "import cytograph as cg\n",
    "import loompy\n",
    "import palettable\n",
    "\n",
    "sys.path.append(os.path.realpath(os.path.join(os.getcwd(), '..', '..')))\n",
    "from scbeta_scrnaseq import utils\n",
    "from scbeta_scrnaseq import vis\n",
    "import scbeta_scrnaseq.cytograph_inmem_utils as cgm\n",
    "import scbeta_scrnaseq.cytograph_analyses as cga\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load loompy objects\n",
    "\n",
    "We parse the inDrops pipeline output files, and create Loom objects for these datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Loom datasets (and immeditely load the counts to memory)\n",
    "samples = [\"x1_S6c\", \"x1_S5c\", \"x1_S4c\", \"x1_S3c\",\"x2_S6c\",\"x2_S5c\", \"x2_S4c\", \"x2_S3c\"]\n",
    "\n",
    "tds = OrderedDict()\n",
    "for tp in samples:\n",
    "    loom_fn = f'../data/complete_processing/{tp}.processed.loom'\n",
    "    tds[tp] = loompy.connect(loom_fn)\n",
    "    tds[tp].vals = sp.sparse.csr_matrix(tds[tp].layers[\"\"][:, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['CellBatch',\n",
       " 'CellID',\n",
       " 'CellProtocol',\n",
       " 'CellStage',\n",
       " 'DetailedLabels',\n",
       " 'HighVarPCA',\n",
       " 'HighVarTSNE',\n",
       " 'Labels',\n",
       " 'NormalizerTotals',\n",
       " 'TSNE',\n",
       " '_TrainFilter',\n",
       " '_Valid']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tds[tp].ca.keys()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for tp in samples:\n",
    "    pds = tds[tp]\n",
    "    full_labels = cgm.CellLabels(pds.ca.Labels, null_label=\"\")\n",
    "\n",
    "for _labels, label_name in [(full_labels, 'labels'),\n",
    "                        (full_labels, 'labels'),\n",
    "                        (detailed_labels, 'det_labels')]:\n",
    "    \n",
    "\n",
    "    tp_pb = cga.pseudobulk_from_label(pds, _labels, norm_total=10**6)\n",
    "    tp_expr = cga.expressed_fraction_from_label(pds, _labels)\n",
    "    \n",
    "    utils.save_df(tp_pb, f'../data/complete_processing/stage6.{label_name}.pseudobulk_tpm.df.npz')\n",
    "    utils.save_df(tp_expr, f'../data/complete_processing/stage6.{label_name}.expr_frac.df.npz')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Across-datasets comparison\n",
    "\n",
    "We are going to need to make a giant merged object to find high-var genes across all datasets, and normalize correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This here is a hacky (but fast) way of combining the sparse counts arrays from each individual dataset\n",
    "all_genes_across_datasets = []\n",
    "for tp in tds.keys():\n",
    "    _tds = tds[tp]\n",
    "    all_genes_across_datasets += list(_tds.ra.Gene)\n",
    "all_genes_across_datasets = sorted(set(all_genes_across_datasets))\n",
    "gene_index = pd.Series(range(len(all_genes_across_datasets)), index=all_genes_across_datasets)\n",
    "\n",
    "new_row = []\n",
    "new_col = []\n",
    "new_data = []\n",
    "n_cells = 0\n",
    "for tp in tds.keys():\n",
    "    _tds = tds[tp]\n",
    "    _coo = _tds.vals.tocoo()\n",
    "    \n",
    "    conv_row = gene_index[_tds.ra.Gene].values[_coo.row]\n",
    "    conv_col = _coo.col + n_cells\n",
    "    n_cells = max(conv_col)\n",
    "    \n",
    "    new_row.append(conv_row)\n",
    "    new_col.append(conv_col)\n",
    "    new_data.append(_coo.data)\n",
    "all_vals = sp.sparse.coo_matrix((np.concatenate(new_data), (np.concatenate(new_row), np.concatenate(new_col)))).tocsr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_selection = cgm.FeatureSelection()\n",
    "feature_selection.fit(None, all_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_genes = 2000\n",
    "_valid = (feature_selection.mu > 0.001)\n",
    "_valid_score = feature_selection.score * _valid[feature_selection.ok].astype(float)\n",
    "high_var_genes = np.where(feature_selection.ok)[0][np.argsort(_valid_score)][-n_genes: ]\n",
    "high_var_genes = np.array(all_genes_across_datasets)[high_var_genes]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read in the pseudo-bulk TPMs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "pb_tpm = {}\n",
    "for pbf in glob.glob('../../*/data/complete_processing/*.pseudobulk_tpm.df.npz'):\n",
    "    key = os.path.basename(pbf)[:-(len('.pseudobulk_tpm.df.npz'))]\n",
    "    pb_tpm[key] = utils.load_df(pbf)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_clusters = []\n",
    "for tp in samples:\n",
    "    for cl in pb_tpm[tp].index:\n",
    "        all_clusters.append((tp, cl))\n",
    "samples_tpm = utils.combine_rows(pb_tpm, all_clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "pb_tpm_z = samples_tpm.copy()\n",
    "pb_tpm_z -= pb_tpm_z.mean()\n",
    "pb_tpm_z /= pb_tpm_z.std(ddof=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.save_df(pb_tpm_z[high_var_genes], '../data/complete_processing/x1x2.pb_tpm.z_scores.highvar.df.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import pdist\n",
    "from fastcluster import linkage\n",
    "from scipy.cluster.hierarchy import dendrogram, leaves_list, fcluster, to_tree, leaders\n",
    "\n",
    "import polo\n",
    "pb_dist = pdist(pb_tpm_z.loc[high_var_genes].values.T, 'correlation')\n",
    "pb_link = linkage(pb_dist, 'average')\n",
    "pb_link = polo.polo.optimal_leaf_ordering(pb_link, pb_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
